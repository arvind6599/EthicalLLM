{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune GPT2 to generate positive reviews\n",
    "> Optimise GPT2 to produce positive IMDB movie reviews using a BERT sentiment classifier as a reward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_bert_training.png' width='600'>\n",
    "<p style=\"text-align: center;\"> <b>Figure:</b> Experiment setup to tune GPT2. The yellow arrows are outside the scope of this notebook, but the trained models are available through Hugging Face. </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "In this notebook we fine-tune GPT2 (small) to generate positive movie reviews based on the IMDB dataset. The model gets the start of a real review and is tasked to produce positive continuations. To reward positive continuations we use a BERT classifier to analyse the sentiment of the produced sentences and use the classifier's outputs as rewards signals for PPO training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers trl wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import trl \n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"lvwerra/gpt2-imdb\",\n",
    "    learning_rate=1.41e-5,\n",
    "    log_with=\"wandb\",\n",
    ")\n",
    "\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marvind-menon\u001b[0m (\u001b[33mdh_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\arvin\\Desktop\\EPFL\\Optional_Project\\ppo_trainer\\wandb\\run-20240226_100010-6tc63to7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7' target=\"_blank\">legendary-universe-3</a></strong> to <a href='https://wandb.ai/dh_lab/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dh_lab/uncategorized' target=\"_blank\">https://wandb.ai/dh_lab/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7' target=\"_blank\">https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x28d9f401d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we load a GPT2 model called `gpt2_imdb`. This model was additionally fine-tuned on the IMDB dataset for 1 epoch with the huggingface [script](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py) (no special settings). The other parameters are mostly taken from the original paper [\"Fine-Tuning Language Models from Human Preferences\"](\n",
    "https://arxiv.org/pdf/1909.08593.pdf). This model as well as the BERT model is available in the Huggingface model zoo [here](https://huggingface.co/models). The following code should automatically download the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IMDB dataset\n",
    "The IMDB dataset contains 50k movie review annotated with \"positive\"/\"negative\" feedback indicating the sentiment.  We load the IMDB dataset into a DataFrame and filter for comments that are at least 200 characters. Then we tokenize each text and cut it to random size with the `LengthSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(config)\n",
    "\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained GPT2 language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the GPT2 model with a value head and the tokenizer. We load the model twice; the first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This serves as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PPOTrainer\n",
    "The `PPOTrainer` takes care of device placement and optimization later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6tc63to7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-universe-3</strong> at: <a href='https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7' target=\"_blank\">https://wandb.ai/dh_lab/uncategorized/runs/6tc63to7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240226_100010-6tc63to7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6tc63to7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\arvin\\Desktop\\EPFL\\Optional_Project\\ppo_trainer\\wandb\\run-20240226_100032-w73ram59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dh_lab/trl/runs/w73ram59' target=\"_blank\">divine-haze-3</a></strong> to <a href='https://wandb.ai/dh_lab/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dh_lab/trl' target=\"_blank\">https://wandb.ai/dh_lab/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dh_lab/trl/runs/w73ram59' target=\"_blank\">https://wandb.ai/dh_lab/trl/runs/w73ram59</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT classifier\n",
    "We load a BERT classifier fine-tuned on the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 953/953 [00:00<00:00, 318kB/s]\n",
      "c:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arvin\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "pytorch_model.bin: 100%|██████████| 669M/669M [03:51<00:00, 2.90MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 39.0/39.0 [00:00<00:00, 12.7kB/s]\n",
      "vocab.txt: 100%|██████████| 872k/872k [00:00<00:00, 1.89MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 56.1kB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)\n",
    "sentiment_pipe1 = pipeline(\"sentiment-analysis\", model=\"omidroshani/imdb-sentiment-analysis\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs are the logits for the negative and positive class. We will use the logits for positive class as a reward signal for the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'NEGATIVE', 'score': 2.3350484371185303}, {'label': 'POSITIVE', 'score': -2.726576328277588}]]\n",
      "[[{'label': 'LABEL_0', 'score': 1.645775556564331}, {'label': 'LABEL_1', 'score': -1.543138027191162}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = \"this movie was really bad!!\"\n",
    "print(sentiment_pipe(text, **sent_kwargs))\n",
    "print(sentiment_pipe1(text, **sent_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'NEGATIVE', 'score': -2.294790267944336}, {'label': 'POSITIVE', 'score': 2.557040214538574}]]\n",
      "[[{'label': 'LABEL_0', 'score': -1.2686774730682373}, {'label': 'LABEL_1', 'score': 1.1461920738220215}]]\n"
     ]
    }
   ],
   "source": [
    "text = \"this movie was really good!!\"\n",
    "print(sentiment_pipe(text, **sent_kwargs))\n",
    "print(sentiment_pipe1(text, **sent_kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation settings\n",
    "For the response generation we just use sampling and make sure top-k and nucleus sampling are turned off as well as a minimal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop consists of the following main steps:\n",
    "1. Get the query responses from the policy network (GPT-2)\n",
    "2. Get sentiments for query/responses from BERT\n",
    "3. Optimize policy with PPO using the (query, response, reward) triplet\n",
    "\n",
    "**Training time**\n",
    "\n",
    "This step takes **~2h** on a V100 GPU with the above specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "\n",
    "param_lambda = 0.5\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs1 = sentiment_pipe(texts, **sent_kwargs)\n",
    "    pipe_outputs2 = sentiment_pipe1(texts, **sent_kwargs)\n",
    "\n",
    "    scores = [[pipe_outputs1[ind][1][\"score\"], pipe_outputs2[ind][1][\"score\"]] for ind in range(len(pipe_outputs1))]\n",
    "\n",
    "    ## mean scores\n",
    "    #rewards = [torch.tensor(s).mean(dim=0)  for s in scores]\n",
    "\n",
    "    ## Uncertainty weighted optimizatio\n",
    "    rewards = [torch.tensor(s).mean(dim=0) - param_lambda*torch.tensor(s).std(dim=0) for s in scores]\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.3511),\n",
       " tensor(2.2657),\n",
       " tensor(1.9542),\n",
       " tensor(1.2679),\n",
       " tensor(1.8520),\n",
       " tensor(1.8753),\n",
       " tensor(1.5749),\n",
       " tensor(0.3942),\n",
       " tensor(0.7615),\n",
       " tensor(-1.9742),\n",
       " tensor(1.4323),\n",
       " tensor(0.5572),\n",
       " tensor(0.8438),\n",
       " tensor(0.3842),\n",
       " tensor(0.5993),\n",
       " tensor(1.7446),\n",
       " tensor(1.7322),\n",
       " tensor(-0.6675),\n",
       " tensor(1.7866),\n",
       " tensor(1.4664),\n",
       " tensor(-2.4002),\n",
       " tensor(-0.4572),\n",
       " tensor(2.2631),\n",
       " tensor(-0.3678),\n",
       " tensor(0.3896),\n",
       " tensor(1.2680),\n",
       " tensor(-1.1418),\n",
       " tensor(2.0233),\n",
       " tensor(0.6250),\n",
       " tensor(0.7169),\n",
       " tensor(1.0640),\n",
       " tensor(2.0852),\n",
       " tensor(2.0095),\n",
       " tensor(1.0673),\n",
       " tensor(1.0639),\n",
       " tensor(2.0888),\n",
       " tensor(0.5871),\n",
       " tensor(1.2086),\n",
       " tensor(0.6123),\n",
       " tensor(1.0531),\n",
       " tensor(1.2714),\n",
       " tensor(-0.8716),\n",
       " tensor(-1.9418),\n",
       " tensor(1.8664),\n",
       " tensor(0.8826),\n",
       " tensor(1.1065),\n",
       " tensor(0.9451),\n",
       " tensor(1.6029),\n",
       " tensor(-0.7631),\n",
       " tensor(0.8570),\n",
       " tensor(0.4068),\n",
       " tensor(1.2871),\n",
       " tensor(0.5749),\n",
       " tensor(0.7306),\n",
       " tensor(1.4834),\n",
       " tensor(0.4924),\n",
       " tensor(1.0197),\n",
       " tensor(-2.1140),\n",
       " tensor(-0.4694),\n",
       " tensor(1.2959),\n",
       " tensor(-1.2997),\n",
       " tensor(-1.3594),\n",
       " tensor(1.5115),\n",
       " tensor(0.4184),\n",
       " tensor(-0.4499),\n",
       " tensor(0.4804),\n",
       " tensor(0.5012),\n",
       " tensor(1.4766),\n",
       " tensor(0.0022),\n",
       " tensor(-0.1188),\n",
       " tensor(0.5099),\n",
       " tensor(0.9324),\n",
       " tensor(0.8822),\n",
       " tensor(-0.0602),\n",
       " tensor(1.7179),\n",
       " tensor(0.5226),\n",
       " tensor(0.4680),\n",
       " tensor(1.5254),\n",
       " tensor(1.2501),\n",
       " tensor(-0.7503),\n",
       " tensor(-0.8893),\n",
       " tensor(0.3359),\n",
       " tensor(1.4556),\n",
       " tensor(2.0681),\n",
       " tensor(-0.9010),\n",
       " tensor(0.7496),\n",
       " tensor(-1.3252),\n",
       " tensor(1.0945),\n",
       " tensor(-0.9201),\n",
       " tensor(1.9580),\n",
       " tensor(1.1330),\n",
       " tensor(0.3138),\n",
       " tensor(-1.1815),\n",
       " tensor(0.8160),\n",
       " tensor(0.6486),\n",
       " tensor(-0.0113),\n",
       " tensor(0.6785),\n",
       " tensor(0.6405),\n",
       " tensor(1.0938),\n",
       " tensor(0.5559),\n",
       " tensor(0.8890),\n",
       " tensor(0.5623),\n",
       " tensor(2.2644),\n",
       " tensor(1.2295),\n",
       " tensor(-0.4951),\n",
       " tensor(0.5199),\n",
       " tensor(0.9935),\n",
       " tensor(-0.7177),\n",
       " tensor(1.4541),\n",
       " tensor(0.3322),\n",
       " tensor(0.8591),\n",
       " tensor(0.0903),\n",
       " tensor(1.0537),\n",
       " tensor(-1.3826),\n",
       " tensor(0.0820),\n",
       " tensor(0.3356),\n",
       " tensor(0.5606),\n",
       " tensor(0.8673),\n",
       " tensor(-1.8673),\n",
       " tensor(-0.0476),\n",
       " tensor(-0.5958),\n",
       " tensor(0.1912),\n",
       " tensor(1.1071),\n",
       " tensor(2.0595),\n",
       " tensor(-1.6413),\n",
       " tensor(-0.8639),\n",
       " tensor(0.4531),\n",
       " tensor(1.0721)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ torch.tensor(s).mean(dim=0) for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.765561819076538,\n",
       " 1.4367839097976685,\n",
       " -1.3036656379699707,\n",
       " 0.43795913457870483,\n",
       " -1.3250980377197266,\n",
       " -2.2311089038848877,\n",
       " 1.3200995922088623,\n",
       " 0.7353010177612305,\n",
       " 1.1265051364898682,\n",
       " -0.6398150324821472,\n",
       " 1.4958276748657227,\n",
       " -1.2330360412597656,\n",
       " 0.2589424252510071,\n",
       " -1.2061372995376587,\n",
       " -0.533473551273346,\n",
       " 1.6424236297607422,\n",
       " 1.7181966304779053,\n",
       " 0.7289050817489624,\n",
       " 0.4377467930316925,\n",
       " 1.8524730205535889,\n",
       " -1.8193843364715576,\n",
       " 0.525845468044281,\n",
       " 1.3357716798782349,\n",
       " 1.6599301099777222,\n",
       " 0.5502035021781921,\n",
       " -0.8797567486763,\n",
       " -2.068617820739746,\n",
       " 0.9794983267784119,\n",
       " -0.21824219822883606,\n",
       " -0.7660068273544312,\n",
       " -1.6335006952285767,\n",
       " 0.7673906683921814,\n",
       " 0.8420900106430054,\n",
       " 2.062904119491577,\n",
       " 2.0531365871429443,\n",
       " 1.8825550079345703,\n",
       " 2.239469289779663,\n",
       " -1.9163490533828735,\n",
       " -1.1391018629074097,\n",
       " -0.253135085105896,\n",
       " 1.6905195713043213,\n",
       " 1.4539309740066528,\n",
       " -0.4656485915184021,\n",
       " 1.1018706560134888,\n",
       " 1.425995111465454,\n",
       " -0.3361194431781769,\n",
       " 0.950605034828186,\n",
       " -0.100822813808918,\n",
       " 1.957603931427002,\n",
       " 0.9814109206199646,\n",
       " 1.8574016094207764,\n",
       " 0.21180176734924316,\n",
       " -0.0320759043097496,\n",
       " 2.070308208465576,\n",
       " 1.1212457418441772,\n",
       " 1.4968822002410889,\n",
       " -1.319556474685669,\n",
       " 1.2088077068328857,\n",
       " 2.214653730392456,\n",
       " -1.8723912239074707,\n",
       " -0.08045332133769989,\n",
       " -0.4475937783718109,\n",
       " -0.4495568871498108,\n",
       " 2.0136008262634277,\n",
       " -0.3817957043647766,\n",
       " 0.09253281354904175,\n",
       " -1.434583067893982,\n",
       " 1.8472990989685059,\n",
       " 0.7679449319839478,\n",
       " 1.3461753129959106,\n",
       " 0.43607449531555176,\n",
       " 0.6617620587348938,\n",
       " 1.893463373184204,\n",
       " 0.10993301123380661,\n",
       " 1.9885666370391846,\n",
       " 2.085772752761841,\n",
       " 0.8017322421073914,\n",
       " -0.26323407888412476,\n",
       " -0.5652740001678467,\n",
       " 1.025005578994751,\n",
       " 1.2420200109481812,\n",
       " 1.7326247692108154,\n",
       " -1.027340054512024,\n",
       " 1.7342698574066162,\n",
       " 1.7357475757598877,\n",
       " -0.6607815623283386,\n",
       " 0.5081457495689392,\n",
       " -0.9517520666122437,\n",
       " -0.2505299746990204,\n",
       " -0.3526282012462616,\n",
       " -0.4086046516895294,\n",
       " -0.04633112624287605,\n",
       " 1.7316994667053223,\n",
       " 2.082430362701416,\n",
       " 0.7415310144424438,\n",
       " -2.1991775035858154,\n",
       " -0.09052298218011856,\n",
       " 1.07755446434021,\n",
       " -1.2521677017211914,\n",
       " 0.6804670095443726,\n",
       " 0.27369585633277893,\n",
       " 2.1565489768981934,\n",
       " 1.851952075958252,\n",
       " 0.5320262312889099,\n",
       " 1.1815072298049927,\n",
       " 0.13623684644699097,\n",
       " 1.755530595779419,\n",
       " -0.392609566450119,\n",
       " 1.3769093751907349,\n",
       " 0.030129335820674896,\n",
       " -0.42504388093948364,\n",
       " 1.541355848312378,\n",
       " 0.451973021030426,\n",
       " 0.8059020638465881,\n",
       " 0.3005434572696686,\n",
       " -1.6917519569396973,\n",
       " 0.9502996206283569,\n",
       " 1.08457612991333,\n",
       " 0.6606417298316956,\n",
       " 1.4530308246612549,\n",
       " 1.0213699340820312,\n",
       " -1.3152424097061157,\n",
       " 0.7743778228759766,\n",
       " 0.7027879357337952,\n",
       " 2.0189316272735596,\n",
       " -0.19654054939746857,\n",
       " 2.186676025390625,\n",
       " 0.2119874209165573]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [[pipe_outputs1[ind][1][\"score\"], pipe_outputs2[ind][1][\"score\"]] for ind in range(len(pipe_outputs1))]\n",
    "\n",
    "rewards = torch.tensor(scores).mean(dim=1)\n",
    "# Assuming you have a tensor named 'tensor'\n",
    "list_of_tensors = rewards.tolist()\n",
    "\n",
    "list_of_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training progress\n",
    "If you are tracking the training progress with Weights&Biases you should see a plot similar to the one below. Check out the interactive sample report on wandb.ai: [link](https://app.wandb.ai/huggingface/trl-showcase/runs/1jtvxb1m/).\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_tuning_progress.png' width='800'>\n",
    "<p style=\"text-align: center;\"> <b>Figure:</b> Reward mean and distribution evolution during training. </p>\n",
    "</div>\n",
    "\n",
    "One can observe how the model starts to generate more positive outputs after a few optimisation steps.\n",
    "\n",
    "> Note: Investigating the KL-divergence will probably show that at this point the model has not converged to the target KL-divergence, yet. To get there would require longer training or starting with a higher initial coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection\n",
    "Let's inspect some examples from the IMDB dataset. We can use `model_ref` to compare the tuned model `model` against the model before optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st watched 5/27</td>\n",
       "      <td>/27/98&lt;|endoftext|&gt;</td>\n",
       "      <td>/82) IMDB</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>0.450167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i must say this movie</td>\n",
       "      <td>wasn't that good at all</td>\n",
       "      <td>was always a shock to me</td>\n",
       "      <td>-2.405393</td>\n",
       "      <td>2.509559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film actually manages to be mindless</td>\n",
       "      <td>goof-offs for</td>\n",
       "      <td>, boring, and</td>\n",
       "      <td>-2.352671</td>\n",
       "      <td>-2.870517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in a not so conventional sense</td>\n",
       "      <td>) and which even a young Ryan Beale could appr...</td>\n",
       "      <td>that it's fifteen years late, Denzel Washingt...</td>\n",
       "      <td>1.602918</td>\n",
       "      <td>-0.982768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love this movie.</td>\n",
       "      <td>Every word you utter and</td>\n",
       "      <td>It's fun to read</td>\n",
       "      <td>2.828364</td>\n",
       "      <td>2.735020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Martin Weisz,</td>\n",
       "      <td>taught that, that</td>\n",
       "      <td>you are either playing</td>\n",
       "      <td>0.656042</td>\n",
       "      <td>-0.074747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I was</td>\n",
       "      <td>eight years old, wonderful of anyone to have ...</td>\n",
       "      <td>definitely gonna try!!! It might be my favori...</td>\n",
       "      <td>2.625557</td>\n",
       "      <td>2.097893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Terrible movie.</td>\n",
       "      <td>Terrible movie.&lt;|endoftext|&gt;</td>\n",
       "      <td>I can't believe he wrote anything. Do yoursel...</td>\n",
       "      <td>-2.913998</td>\n",
       "      <td>-2.777426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The sequel to</td>\n",
       "      <td>'The Childkillers,' starring Carole Lomb</td>\n",
       "      <td>2001: A Space Odyssey described as \"the</td>\n",
       "      <td>0.315910</td>\n",
       "      <td>1.161687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I guess that</td>\n",
       "      <td>out of all the previous films I've seen with ...</td>\n",
       "      <td>this movie was made in 1932, maybe it was mad...</td>\n",
       "      <td>1.364934</td>\n",
       "      <td>-0.613506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>An MGM MINIATURE Short Subject</td>\n",
       "      <td>I prefer to see this one on the Bonus VHS tape</td>\n",
       "      <td>MINIATURE Short Subject on The Sunday Times M...</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>0.760985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Don't waste 90 minutes</td>\n",
       "      <td>with some rubbish, I suppose, but this movie ...</td>\n",
       "      <td>watching this film. (on a recommendation for ...</td>\n",
       "      <td>-1.779454</td>\n",
       "      <td>0.716841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>this is</td>\n",
       "      <td>what Michael Hedges had in mind when he</td>\n",
       "      <td>something that some older friends and now i c...</td>\n",
       "      <td>1.441942</td>\n",
       "      <td>1.609697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>When this film was made, the</td>\n",
       "      <td>same production values that made this, the sa...</td>\n",
       "      <td>sense to me was as if the psychiatrist wanted...</td>\n",
       "      <td>1.241216</td>\n",
       "      <td>0.910149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I found this film to be the</td>\n",
       "      <td>best adaptation I could find. I'd buy</td>\n",
       "      <td>second underpropunce story starring Carmilla</td>\n",
       "      <td>2.265382</td>\n",
       "      <td>0.732059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Actually, the</td>\n",
       "      <td>movie has no doubt low-grade special</td>\n",
       "      <td>suits dealing with the \"Seven Seas\"</td>\n",
       "      <td>-0.277223</td>\n",
       "      <td>0.054741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        query  \\\n",
       "0                            1st watched 5/27   \n",
       "1                       i must say this movie   \n",
       "2   This film actually manages to be mindless   \n",
       "3              in a not so conventional sense   \n",
       "4                          I love this movie.   \n",
       "5                               Martin Weisz,   \n",
       "6                                       I was   \n",
       "7                             Terrible movie.   \n",
       "8                               The sequel to   \n",
       "9                                I guess that   \n",
       "10             An MGM MINIATURE Short Subject   \n",
       "11                     Don't waste 90 minutes   \n",
       "12                                    this is   \n",
       "13               When this film was made, the   \n",
       "14                I found this film to be the   \n",
       "15                              Actually, the   \n",
       "\n",
       "                                    response (before)  \\\n",
       "0                                 /27/98<|endoftext|>   \n",
       "1                             wasn't that good at all   \n",
       "2                                       goof-offs for   \n",
       "3   ) and which even a young Ryan Beale could appr...   \n",
       "4                            Every word you utter and   \n",
       "5                                   taught that, that   \n",
       "6    eight years old, wonderful of anyone to have ...   \n",
       "7                        Terrible movie.<|endoftext|>   \n",
       "8            'The Childkillers,' starring Carole Lomb   \n",
       "9    out of all the previous films I've seen with ...   \n",
       "10     I prefer to see this one on the Bonus VHS tape   \n",
       "11   with some rubbish, I suppose, but this movie ...   \n",
       "12            what Michael Hedges had in mind when he   \n",
       "13   same production values that made this, the sa...   \n",
       "14              best adaptation I could find. I'd buy   \n",
       "15               movie has no doubt low-grade special   \n",
       "\n",
       "                                     response (after)  rewards (before)  \\\n",
       "0                                           /82) IMDB          0.028346   \n",
       "1                            was always a shock to me         -2.405393   \n",
       "2                                       , boring, and         -2.352671   \n",
       "3    that it's fifteen years late, Denzel Washingt...          1.602918   \n",
       "4                                    It's fun to read          2.828364   \n",
       "5                              you are either playing          0.656042   \n",
       "6    definitely gonna try!!! It might be my favori...          2.625557   \n",
       "7    I can't believe he wrote anything. Do yoursel...         -2.913998   \n",
       "8             2001: A Space Odyssey described as \"the          0.315910   \n",
       "9    this movie was made in 1932, maybe it was mad...          1.364934   \n",
       "10   MINIATURE Short Subject on The Sunday Times M...          0.881107   \n",
       "11   watching this film. (on a recommendation for ...         -1.779454   \n",
       "12   something that some older friends and now i c...          1.441942   \n",
       "13   sense to me was as if the psychiatrist wanted...          1.241216   \n",
       "14       second underpropunce story starring Carmilla          2.265382   \n",
       "15                suits dealing with the \"Seven Seas\"         -0.277223   \n",
       "\n",
       "    rewards (after)  \n",
       "0          0.450167  \n",
       "1          2.509559  \n",
       "2         -2.870517  \n",
       "3         -0.982768  \n",
       "4          2.735020  \n",
       "5         -0.074747  \n",
       "6          2.097893  \n",
       "7         -2.777426  \n",
       "8          1.161687  \n",
       "9         -0.613506  \n",
       "10         0.760985  \n",
       "11         0.716841  \n",
       "12         1.609697  \n",
       "13         0.910149  \n",
       "14         0.732059  \n",
       "15         0.054741  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the reward mean/median of the generated sequences we observe a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)    0.345186\n",
       "rewards (after)     0.401240\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "median:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)    0.768574\n",
       "rewards (after)     0.724450\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Finally, we save the model and push it to the Hugging Face for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2-imdb-pos-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-imdb-pos-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\trl\\models\\modeling_base.py:558\u001b[0m, in \u001b[0;36mPreTrainedModelWrapper.save_pretrained\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state_dict, save_path)\n\u001b[0;32m    556\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\transformers\\modeling_utils.py:2322\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[0;32m   2320\u001b[0m     commit_message \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommit_message\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2321\u001b[0m     repo_id \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_directory\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 2322\u001b[0m     repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_repo(repo_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2323\u001b[0m     files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(save_directory)\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;66;03m# Only save the model itself if we are using distributed training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\transformers\\utils\\hub.py:676\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[1;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[0;32m    673\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    674\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 676\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mrepo_id\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\hf_api.py:3162\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[1;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[0;32m   3158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lfsmultipartthresh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3159\u001b[0m     \u001b[38;5;66;03m# Testing purposes only.\u001b[39;00m\n\u001b[0;32m   3160\u001b[0m     \u001b[38;5;66;03m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001b[39;00m\n\u001b[0;32m   3161\u001b[0m     json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlfsmultipartthresh\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lfsmultipartthresh  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 3162\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hf_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3164\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   3165\u001b[0m     r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mpost(path, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mjson)\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\hf_api.py:8191\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[1;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   8188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8189\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[0;32m   8190\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m-> 8191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_hf_headers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_write_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:122\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Get auth token to send\u001b[39;00m\n\u001b[0;32m    121\u001b[0m token_to_send \u001b[38;5;241m=\u001b[39m get_token_to_send(token)\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_validate_token_to_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_to_send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_write_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Combine headers\u001b[39;00m\n\u001b[0;32m    125\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: _http_user_agent(\n\u001b[0;32m    127\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m     )\n\u001b[0;32m    131\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\arvin\\anaconda3\\envs\\dh_lab\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:172\u001b[0m, in \u001b[0;36m_validate_token_to_send\u001b[1;34m(token, is_write_action)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_write_action:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is required (write-access action) but no token found. You need\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m         )\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_org\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must use your personal account token for write-access methods. To\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m generate a write-access token, go to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"gpt2-imdb-pos-v2\", push_to_hub=True)\n",
    "tokenizer.save_pretrained(\"gpt2-imdb-pos-v2\", push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c8ff454cd947027f86954d72bf940c689a97dcc494eb53cfe4813862c6065fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
